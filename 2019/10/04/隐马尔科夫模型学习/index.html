<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="参数定义HMM由隐含状态S、可观测状态O、初始状态概率矩阵π、隐含状态转移概率矩阵A、可观测值转移矩阵B(又称为混淆矩阵，Confusion Matrix)；π和A决定了状态序列，B决定观测序列，因此HMM可以使用三元符号表示，称为HMM的三元素：  \lambda = (A,B,\pi)S为所有可能状态集合，O是所有可能的观测集合,I是长度为T的状态序列，Q是对应的观测序列：  \begin{">
<meta property="og:type" content="article">
<meta property="og:title" content="隐马尔科夫模型学习">
<meta property="og:url" content="http://yoursite.com/2019/10/04/隐马尔科夫模型学习/index.html">
<meta property="og:site_name" content="WeiGuangLi">
<meta property="og:description" content="参数定义HMM由隐含状态S、可观测状态O、初始状态概率矩阵π、隐含状态转移概率矩阵A、可观测值转移矩阵B(又称为混淆矩阵，Confusion Matrix)；π和A决定了状态序列，B决定观测序列，因此HMM可以使用三元符号表示，称为HMM的三元素：  \lambda = (A,B,\pi)S为所有可能状态集合，O是所有可能的观测集合,I是长度为T的状态序列，Q是对应的观测序列：  \begin{">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191004210509.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191004211120.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191005212530.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006110012.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/204730bgsxxbztb8xbgdza.gif">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006000433.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006000651.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006000922.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006001002.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006003947.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006004030.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152253.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152358.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152434.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152547.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152629.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152713.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152939.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153026.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153226.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153333.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153414.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153509.png">
<meta property="og:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153544.png">
<meta property="og:updated_time" content="2019-10-06T07:35:56.329Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="隐马尔科夫模型学习">
<meta name="twitter:description" content="参数定义HMM由隐含状态S、可观测状态O、初始状态概率矩阵π、隐含状态转移概率矩阵A、可观测值转移矩阵B(又称为混淆矩阵，Confusion Matrix)；π和A决定了状态序列，B决定观测序列，因此HMM可以使用三元符号表示，称为HMM的三元素：  \lambda = (A,B,\pi)S为所有可能状态集合，O是所有可能的观测集合,I是长度为T的状态序列，Q是对应的观测序列：  \begin{">
<meta name="twitter:image" content="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191004210509.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/10/04/隐马尔科夫模型学习/">





  <title>隐马尔科夫模型学习 | WeiGuangLi</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">
<div class="bg_content">
<canvas id="canvas"></canvas>
</div>
  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WeiGuangLi</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/04/隐马尔科夫模型学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="lwglucky">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WeiGuangLi">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">隐马尔科夫模型学习</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-04T21:07:56+08:00">
                2019-10-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/智能算法/" itemprop="url" rel="index">
                    <span itemprop="name">智能算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191004210509.png" alt="马尔科夫链模型"></p>
<h3><span id="参数定义">参数定义</span></h3><p><strong>HMM</strong>由隐含状态S、可观测状态O、初始状态概率矩阵π、隐含状态转移概率矩阵A、可观测值转移矩阵B(又称为混淆矩阵，Confusion Matrix)；π和A决定了状态序列，B决定观测序列，因此HMM可以使用三元符号表示，称为HMM的三元素：</p>
<script type="math/tex; mode=display">
\lambda = (A,B,\pi)</script><p>S为所有可能状态集合，O是所有可能的观测集合,I是长度为T的状态序列，Q是对应的观测序列：</p>
<script type="math/tex; mode=display">
\begin{aligned}
    S=\{s_1,s_2, \cdots ,S_n \}  \quad  O=\{o_1,o_2,\cdots ,o_m \} \\
    I=\{i_1,i_2, \cdots , i_T\}  \quad  Q=\{q_1,q_2, \cdots , q_T \}
\end{aligned}</script><p><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191004211120.png" alt="case"></p>
<p>S={下雨，阴天，晴天}；<br>O={地上干，地上湿}<br>I = {晴，雨，雨，阴，晴，阴}<br>Q={干，湿，湿，湿，干，干}</p>
<p>A是隐含状态转移概率矩阵,其中aij是在时刻t处于状态si的条件下时刻t+1转移到状态sj的概率。a晴雨 = 某天是晴天条件下，下一天是雨天的概率。 （某一时刻→下一时刻）$a_{ij}=p(i_{t+1}=s_j|i_t=s_i)$:</p>
<script type="math/tex; mode=display">
A=[a_{ij}]_{n \times n} = \left [ {
\begin{matrix}
    a_{11} & a_{12} & \cdots & a_{1n} \\
    a_{21} & a_{22} & \cdots & a_{2n} \\
    \cdots  & \cdots  & \cdots  & \cdots \\
    a_{n1} & a_{n2} & \cdots & a_{nn} 
\end{matrix}
} \right]</script><p>B是可观测值转移概率矩阵,其中$b_{ij}$是在时刻t处于状态si的条件下生成观测值oj的概率。b晴干 = 某天是晴天条件下，某天是地是干的的概率。 （同一时刻）:$b_{ij}=p(q_t=o_j|i_t=s_i)$.</p>
<script type="math/tex; mode=display">
B=[b_{ij}]_{n \times m} = \left [ {
\begin{matrix}
    b_{11} & b_{12} & \cdots & b_{1n} \\
    b_{21} & b_{22} & \cdots & b_{2n} \\
    \cdots  & \cdots  & \cdots  & \cdots \\
    b_{n1} & b_{n2} & \cdots & b_{nn} 
\end{matrix}
} \right]</script><p>π是初始状态概率向量: $\pi=(\pi_i)_{1 \times n}=(\pi_1,\pi_2,\cdots,\pi_n)$.</p>
<p>性质1： 最终分析结果发现，在第t时刻发生状态的概率it只和t-1时刻有关。<br>         性质2： 第t时刻的观测值qt只和第t时刻的状态it有关。</p>
<h3><span id="case">case:</span></h3><p>假设有三个盒子，编号为1,2,3；每个盒子都装有黑白两种颜色的小球，球的比例。如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>编号</th>
<th>白球</th>
<th>黑球</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>4</td>
<td>6</td>
</tr>
<tr>
<td>2</td>
<td>8</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>5</td>
<td>5</td>
</tr>
</tbody>
</table>
</div>
<p>按照下列规则的方式进行有放回的抽取小球，得到球颜色的观测序列：<br> 1、按照π的概率选择一个盒子，从盒子中随机抽取出一个球，记录颜色后放回盒子中；<br> 2、按照某种条件概率选择新的盒子，重复该操作；<br> 3、最终得到观测序列：“白黑白白黑”</p>
<ol>
<li>S={盒子1，盒子2，盒子3}</li>
<li>O={白，黑}</li>
<li>观测序列的长度 T=5 </li>
<li>抽到1盒子的概率是0.2，抽到2盒子的概率是0.5，抽到3盒子的概率是0.3: π={0.2 0.5 0.3}</li>
<li>转移矩阵: $A=\left[ { \begin{matrix}<br>0.5 &amp; 0.4 &amp; 0.1 \\ 0.2 &amp; 0.2 &amp; 0.6 \\ 0.2 &amp; 0.5 &amp; 0.3<br>\end{matrix} } \right]$</li>
<li>观测矩阵:$B=\left[ { \begin{matrix}<br> 0.4 &amp; 0.6 \\ 0.8 &amp; 0.2 \\ 0.5 &amp; 0.5<br>\end{matrix} } \right] $ </li>
</ol>
<p>给定参数π、A、B的时候，得到观测序列为“白黑白白黑”的概率是多少?<br>这个时候，不知道隐含条件，即不知道状态值：①→③→②→②→③ ；<br>如何根据π、A、B求出测序列为“白黑白白黑”的概率？</p>
<p>引入HMM的三个问题：</p>
<p>1、概率计算问题:<br>前向-后向算法 给定模型λ=(A,B,π)和观测序列Q={q1,q2,…,qT}，计算模型λ下观测到序列Q出现的概率P(Q|λ)；回顾上面的案例，λ=(A,B,π)已知。观测到序列 Q=白→黑→白→白→黑，但我们不知道 状态序列 I=①→③→②→②→③；我们要求解P(Q|λ)，即Q=白→黑→白→白→黑 这个观测序列发生的概率。可以用前向-后向算法来实现。</p>
<p>2、学习问题:<br>Baum-Welch算法(状态未知) 已知观测序列Q={q1,q2,…,qT}，估计模型λ=(A,B,π)的参数，使得在该模型下观测序列P(Q|λ)最大。Baum-Welch算法是EM算法的一个特例，专门用来求解隐马尔科夫中隐状态参数λ=(A,B,π)。即：根据已知的观测到序列 Q=白→黑→白→白→黑，去寻找整个模型的一组隐状态参数λ=(A,B,π)，使得在模型中观测序列发生的可能性P(Q|λ)最大。</p>
<p>3、预测问题：<br>Viterbi算法 给定模型λ=(A,B,π)和观测序列Q={q1,q2,…,qT}，求给定观测序列条件概率P(I|Q，λ)最大的状态序列I。已知观测到序列 Q=白→黑→白→白→黑，当我们得到λ=(A,B,π)后，我们用Viterbi算法 求出在哪一种状态序列发生的可能性最大，即，求出状态序列 I=①→③→②→②→③；即，抽取什么样的盒子顺序，更可能得到白→黑→白→白→黑这种结果。</p>
<p><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191005212530.png" alt="HMM"><br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006110012.png" alt="symbol定义"><br>$A_{N \times N}={a_{ij}}$表示$a_{ij}=P(state \ q_j \ at \ t+1 | state \ q_i \ at \ t)$.</p>
<p><strong>注意推导: 状态$x_0$的概率为 $π_{x_0}$。在$x_0$的条件下观测到$O_0$的概率是$b_{x_0}(O_0)$，从$x_0$转移到$x_1$的概率为$a_{x_0,x_1}$。依次类推</strong> </p>
<p>定义状态链 $ X = (X_0, X_1, X_2, …, X_{T-1}) $。<br>(1)只看HMM图中虚线上半部分，相当于给定模型λ，求状态链X的概率:</p>
<script type="math/tex; mode=display">
P(X|λ)=π_{x_0}a_{x_0,x_1}a_{x_1,x_2}...a_{x_{T-2},x_{T-1}}</script><p>(2)只看HMM图中虚线下半部分，相当于在给定了状态链X和模型λ，求观测链O的概率:</p>
<script type="math/tex; mode=display">
P(O|X,\lambda)=b_{x_0}(O_0)b_{x_1}(O_1) \cdots B_{x_{T-1}}(O_{T-1})</script><p>(3) 按联合概率有：</p>
<script type="math/tex; mode=display">
P(O|X,\lambda)=P(O|X,\lambda)P(X|\lambda)</script><p>按照公式推导也有：</p>
<script type="math/tex; mode=display">
\begin{aligned}
 P(O,X|λ) & = \frac{P(O \cap X \cap \lambda )}{P(\lambda)}  \\
 P(O|X,\lambda)P(X| \lambda) & =\frac{P(O \cap X \cap \lambda )}{P(X \cap \lambda)} \cdot 
 \frac{P(X \cap \lambda )}{P(\lambda)} =\frac{P(O \cap X \cap \lambda )}{P(\lambda)}
\end{aligned}</script><p>(4)再按概率公式展开P(O|λ)，即:(<strong>好好看看这个式子</strong>)</p>
<script type="math/tex; mode=display">
\begin{aligned}
    P(O|λ) & = ∑_X P(O,X|λ) \\
    & = ∑_X P(O|X,λ)P(X|λ) \\
    & = ∑_X π_{x_0}b_{x_0}(O_0)a_{x_0,x_1}b_{x_1}(O_1) \cdots a_{x_{T-2},x_{T-1}}b_{x_{T-1}}(O_{T-1})
\end{aligned}</script><p>这种算法虽然直观，但是计算量非常大,概念上可行，但是计算不上可行。</p>
<p><strong>前向概率</strong>:$\alpha _t(i)$，它表示到时刻t时，观测序列为$o_1, o_2, o_3, …,o_t$，且状态为q_i的概率，记作：</p>
<script type="math/tex; mode=display">
\alpha _t(i)=P(O_0,O_1, \cdots , O_t, x_t=q_i|λ)</script><p><strong><font color="#dd0000"><u>注意这里是$\alpha$不是a,注意区分</u></font></strong><br>         递归算法:</p>
<ol>
<li>计算初始的前向概率$\alpha_0(i)$:<script type="math/tex; mode=display">
Let: \quad \alpha _0(i)=π_ib_i(O_0), for i=0,1,...,N-1</script>$B_{N \times M}={b_j(k)}$代表$b_j(k)=P(observation \ k \ at \ t | state \ q_j \ at \ t)$.</li>
<li>联系t-1时刻的前向概率$\alpha_{t-1}(j)$与t时刻的前向概率 $\alpha_t(i)$. For  t=1,2,…,T-1 and i=0,1,…,N-1,计    算:<script type="math/tex; mode=display">
 \alpha _t(i)=\left[ { ∑ _{j=0}^{N-1}\alpha _{t-1}(j)\alpha_{ji} } \right]b_i(O_t)</script></li>
<li>当运行到最后一个前向概率时，所有的计算都完成了，即获取到P(O|λ)，具体的式子如下：<script type="math/tex; mode=display">
 P(O|λ)=∑_{i=0}^{N-1}a_{T-1}(i)</script></li>
</ol>
<h4><span id="case">case:</span></h4><h3><span id="解码问题">解码问题</span></h3><p>已知HMM模型λ=(A, B, π)，以及观测序列O，求最可能的状态序列。<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/204730bgsxxbztb8xbgdza.gif" alt="解码"></p>
<p>Viterbi算法的思想是步步为营，每一步都是当前最佳的路。如果用气温和年轮的例子来说：</p>
<ol>
<li>首先写出第一年的情况<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006000433.png" alt="Viterbi-1"><br>因为第一年观测到的是小年轮，于是δ1(H)表示第一年观测到小年轮的同时气温为高温的概率：$δ1(H) = 0.6×0.1=0.06$,注：其中0.6表示初始为H的概率，0.1表示观测到小年轮而且为高温的概率。同时，第一年观测到小年轮而且气温为低温的概率为：$δ1(C) = 0.4×0.7=0.28$, δ1(C) &gt;δ1(H)，因此第一年为低温的可能性更大，所以下一步计算时不考虑第一年为高温的情况</li>
<li>计算第二年的情况:<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006000651.png" alt="Viterbi-2"><br>第二年观测到的是中年轮(M)，于是δ2(H) =δ1(C)×0.4×0.4 = 0.0448,注：第一个0.4表示由低温转高温的概率，第二个0.4为观测为中年轮，且状态为高温的概率,同理，δ2(C) =δ1(C)×0.6×0.2 = 0.0336,δ2(H) &gt;δ2(C)，因此第二年为高温的可能性更大，所以下一步计算时不考虑第二年为低温的情况。</li>
<li>计算第三年的情况:<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006000922.png" alt="Viterbi-3"><br>第三年观测为小年轮，计算方法同第二年，直接写出结果如下：δ3(H) =δ2(H)×0.7×0.1 = 0.003136,δ3(C) =δ2(H)×0.3×0.7 = 0.009408,δ3(C) &gt;δ3(H)，因此第三年是低温的可能更高，所以下一步计算时不考虑第三年为高温的情况。</li>
<li>计算第四年的情况<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006001002.png" alt="Viterbi-4"><br>第四年观测为大年轮，计算方法同第二年，直接写出结果如下：δ4(H) =δ3(C)×0.4×0.5 = 0.0018816,δ4(C) =δ3(C)×0.6×0.1 = 0.00056448,δ3(H) &gt;δ3(C)，因此第四年是高温的可能更高。综上，这四年最可能的状态是C-H-C-H，这一结果和第一篇隐马尔科夫简介博文(<a href="http://blog.sciencenet.cn/blog-2970729-1188964.html)中HMM算法得到的结果一致。但是通过计算过程来看，更加高效。" target="_blank" rel="noopener">http://blog.sciencenet.cn/blog-2970729-1188964.html)中HMM算法得到的结果一致。但是通过计算过程来看，更加高效。</a></li>
</ol>
<p><strong>这里没有公式推导，姑且先记着吧,也不难</strong></p>
<h3><span id="学习问题-learning-problem">学习问题 (Learning Problem)</span></h3><p><a href="http://blog.sciencenet.cn/blog-2970729-1192951.html" target="_blank" rel="noopener">http://blog.sciencenet.cn/blog-2970729-1192951.html</a><br>已知观测序列$O=(o_0, o_1, o_2, o_3, …, o_{T-1})$，需通过调整HMM的参数λ= (A, B, π)使是概率P(O|λ)最大。</p>
<p>第一类问题(Evaluation Problem)中有介绍到前向算法(Forward Algorithm)，其中前向概率:</p>
<script type="math/tex; mode=display">
a_t(i)=P(O_0,O_1,...,O_t,x_t=q_i|λ)</script><p>后向算法(Backward Algorithm):</p>
<script type="math/tex; mode=display">
β_t(i)=P(O_{t+1},O_{t+2},...,O_T|x_t=q_i,λ)</script><p>(1) E-step<br>先定义两个变量$ξ_t(i, j)$和$γ_t(i)$：</p>
<script type="math/tex; mode=display">
\begin{aligned}
ξ_t(i, j) & =\frac{\alpha_t(i)a_{ij}b_j(o_{t+1})β_{t+1}(j)}{P(O|λ)} \\
& = \frac{\alpha_t(i)a_{ij}b_j(o_{t+1})β_{t+1}(j)}
{∑_{i=1}^N∑_{i=1}^N \alpha _t(i)a_{ij}b_j(O_{t+1})β_{t+1}(j)}
\end{aligned}</script><script type="math/tex; mode=display">
\begin{aligned}
γ_t(i) & = P(x_t=q_i|O,λ)  =∑_{j=1}^N ξ_t(i, j) \\
& = \frac{\alpha_t(i)β_t(i)}{∑_{i=1}^N \alpha_t(i)β_t(i)}
\end{aligned}</script><p>这两个变量看起来好像很复杂，但是它们想要表达的概念并不复杂。$ξ_t(i, j)$表示在t时刻状态为i，在t+1时刻状态转为状态j的概率。再具体一些来讲，例如$ξ_2(H, L)$表示第二年是高温(H)，而第三年为低温(L)的概率。</p>
<p>而$γ_t(i)$表示t时刻为状态i的概率，例如$γ_2(H)$表示第二年是高温(H)，而第三年为低温(L)或高温(H)的概率之和，也即仅考虑第二年为高温(H)的概率。<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006003947.png" alt="AA"><br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006004030.png" alt="AAA"></p>
<p>(2) M-step<br>有了上述的两个式子后，我们可以轻松地写出当前状态转移矩阵中A的元素$a_{ij}$和观测矩阵B中的元素$b_j(k)$：</p>
<script type="math/tex; mode=display">
\hat a_{ij}=\frac{∑ξ_t(i, j)}{∑γ_t(i)}</script><p>理解这个式子:<br>打个比方，如果用aHL表示当前参数条件下整个链中由高温转低温的概率，那么式子中的分子表示所有（t从第一年至倒数第二年，因为是有转移，这里是写为到倒数第二年）高温(H)转到低温(L)时刻的概率之和；分母t时刻为高温(H)的概率(无论t+1时刻的状态是什么)。两者相除即由i状态转移到j状态的概率。</p>
<script type="math/tex; mode=display">
\hat b_{k}=\frac{∑_{t,o_t=k}γ_t(j)}{∑γ_t(j)}</script><p>式子中，分子是所有满足观测为k的这些时刻，状态为j的概率之和.例如所有观测到大年轮(L)的那些年份状态为高温(H)的期望值；分母为所有t时刻(第一年至倒数第二年)状态为j的概率之和，例如在所有年份中状态为高温(H)的期望值。两者相除即观测为k时状态为j的概率，即由状态j转为观测k的概率。<br>另外，还需指定初始状态分布。如果有经验值，可按照经验；如果没有可随机取值：</p>
<script type="math/tex; mode=display">
\hat{π}=γ_1(i)</script><p>这样就获取到当前状态(t=1)的转移矩阵A1和当前观测矩阵B1，以及初始状态π，即当前λ1=(A1, B1, π)。<br>(3) 用λ1代替λ0，不断地迭代M-step和E-step，直到收敛<br>在计算的过程中通常会用log函数来简化计算，因此也即：</p>
<script type="math/tex; mode=display">
logP(O|λ)-logP(O|λ_0)<d></script><p>或者直接指定迭代多少次后就退出迭代过程，终止计算.</p>
<h4><span id="case">case</span></h4><p>晴雨预测例子，假设观测了三天，观测结果为O={o1=soggy, o2=dry, o3=dryish}。再次强调，实际应用中，必须要有足够多的信息才能得到较好的结果，也就是说观测链通常会比较长。这里为了简化计算，观测链长度仅为3。<br>先初始化一组参数λ1=(A1, B1, π)，其中的值是随机的(当然如果有经验的人可以找到一些初始化里的细微套路，使得算出的局部最优解为全局最优解的可能性更大)，本例中设置的值如下：<br>=&gt; 状态转移矩阵A1<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152253.png" alt="状态转移矩阵A1"><br>=&gt; 初始状态分布π<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152358.png" alt="初始状态分布π"><br>=&gt; 观测矩阵B1<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152434.png" alt="观测矩阵B1"><br>将状态转移矩阵A1和观测矩阵B1的所有元素标记在一张图中，如下：<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152547.png" alt="示意图"><br>(1) 基于以上数据，利用向前向后算法计算出所有的前向概率和后向概率<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152629.png" alt="dfe"><br>再利用前向算法计算t=2和t=3时的前向概率，如下：<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152713.png" alt="dwsw"><br>在计算完前向概率后，我们可以算出在当前参数条件下，观测链O出现的概率：<br>P(O|λ1)=α3(1) +α3(2)+α3(3)=0.013<br>同理我们也计算出所有的后向概率。注意：后向概率是从后往前算的(即先计算t=3，再算t=2，最后算t=1)，t=3时：</p>
<script type="math/tex; mode=display">
β_3(1)=β_2(1)=β_1(1)=1</script><p>再利用后向算法求出所有的后向概率：<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006152939.png" alt="dwx"><br>(2) 计算中间变量ξt(i, j)和γt(i)<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153026.png" alt="dwaa"><br>(3) 计算当前的参数λ2=(A2, B2, π)，并用当前的参数代替λ1，完成一次迭代<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153226.png" alt="vdwss"><br>(4) 不断迭代直到收敛<br>这里将t=1和t=2时计算结果列出来.<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153333.png" alt="yrr"><br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153414.png" alt="ssswsc"></p>
<p>可以看到表中P(O|Δ)变化较大，表明未收敛。<br>注：这里写的P(O|Δ)就是上文中的P(O|λ)，只是写法不同，内容一致当迭代至第9次后结果收敛，计算终止。如下表<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153509.png" alt="llk"></p>
<p>因此，最终结果如下表：<br><img src="https://raw.githubusercontent.com/lwglucky/BLOG/master/20191006153544.png" alt="ww"></p>
<h4><span id="参考材料">参考材料：</span></h4><p><a href="https://sens.tistory.com/m/320?category=501289" target="_blank" rel="noopener">https://sens.tistory.com/m/320?category=501289</a></p>
<p>Guy Leonard Kouemou. History and Theoretical Basics of Hidden Markov Models</p>
<p>Mark Stamp. A Revealing Introduction to Hidden Markov Models</p>
<p>李航. 统计学习方法</p>
<p><a href="http://blog.sciencenet.cn/blog-2970729-1188964.html" target="_blank" rel="noopener">http://blog.sciencenet.cn/blog-2970729-1188964.html</a></p>
<p>[1] Dmitry Shemetov. Bayesian structural inference and the Baum-Welch algorithm.</p>
<p>[2] Leonard E. Baum, Ted Petrie, George Soules and Norman Weiss. A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains.</p>
<p>[3] Loc Nguyen. Tutorial on Hidden Markov Mode</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/10/04/隐马尔科夫模型HMM/" rel="next" title="隐马尔科夫模型HMM">
                <i class="fa fa-chevron-left"></i> 隐马尔科夫模型HMM
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/10/07/图像单应性/" rel="prev" title="图像单应性">
                图像单应性 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">lwglucky</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#null"><span class="nav-number">1.</span> <span class="nav-text">参数定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#null"><span class="nav-number">2.</span> <span class="nav-text">case:</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#null"><span class="nav-number">2.1.</span> <span class="nav-text">case:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#null"><span class="nav-number">3.</span> <span class="nav-text">解码问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#null"><span class="nav-number">4.</span> <span class="nav-text">学习问题 (Learning Problem)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#null"><span class="nav-number">4.1.</span> <span class="nav-text">case</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#null"><span class="nav-number">4.2.</span> <span class="nav-text">参考材料：</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lwglucky</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
<!-- ҳ����С���� -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
<script type="text/javascript" src="/js/src/dynamic_bg.js"></script>